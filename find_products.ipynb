{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "def get_prompt(message: str):\n",
    "    return f\"\"\"\n",
    "    Identify the following item from the telegram chat message, written in Russian: \n",
    "    - What product is the user interested in\n",
    "    \n",
    "    The message is delimited with triple backticks. \\\n",
    "    Format your response as a JSON object with \\\n",
    "    \"products\" as the keys. \n",
    "    If the information isn't present, use \"\" \\\n",
    "    as the value.\n",
    "  \n",
    "    Message: '''{message}'''\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('channel_messages.json', 'r', encoding=\"utf8\") as f:\n",
    "    messages = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "products = []\n",
    "for message in tqdm(messages):\n",
    "    prompt = get_prompt(message)\n",
    "    gpt_answer = json.loads(get_completion(prompt))\n",
    "    if type(gpt_answer.get('products', [])) == str:\n",
    "        if gpt_answer.get('products', []).strip() == '':\n",
    "              continue\n",
    "        else:\n",
    "            gpt_answer['products'] = [gpt_answer.get('products')]\n",
    "    \n",
    "    if len(gpt_answer.get('products', [])) < 1:\n",
    "        continue\n",
    "    else:\n",
    "        products.append({\n",
    "            'date': message.get('date', ''),\n",
    "            'user_id': message.get('user_id', ''),\n",
    "            \"message_id\": message.get('message_id', ''),\n",
    "            'products': gpt_answer.get('products', ''),\n",
    "        })\n",
    "with open('product_requests.json', 'w', encoding='utf8') as outfile:\n",
    "\t\tjson.dump(products, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#message = \"\"\"Ð ÐµÐ±ÑÑ‚Ð°, Ð½Ðµ Ð·Ð½Ð°ÐµÑ‚Ðµ Ð³Ð´Ðµ ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ Ð»Ð¾Ð¿Ð°Ñ‚Ñƒ Ð´Ð»Ñ Ð²Ñ‹Ð¿ÐµÑ‡ÐºÐ¸ Ð¿Ð¸Ñ†Ñ†Ñ‹ Ð¸ ÑÐ¾ÐµÐ²Ð¾Ðµ Ð¼Ð¾Ð»Ð¾ÐºÐ¾ Alpro?\"\"\"\n",
    "#message = \"\"\"Ð’ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð²ÐµÑ‚! ÐŸÐ¾Ð´ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¿Ð¾ Ð¾Ð²ÑÑÐ½Ð¾Ð¼Ñƒ Ð¼Ð¾Ð»Ð¾ÐºÑƒ, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð° ðŸ™ðŸ» Ð¿Ð¾ÐºÑƒÐ¿Ð°Ð»Ð° NÐµÐ¼Ð¾Ð»Ð¾ÐºÐ¾ Ð² Ñ„Ð¸ÐºÑ Ð¿Ñ€Ð°Ð¹ÑÐµ Ð¿Ð¾Ð» Ð³Ð¾Ð´Ð°, Ð° Ñ‚ÐµÐ¿ÐµÑ€ÑŒ ÐµÐ³Ð¾ Ñ‚Ð°Ð¼ Ð½ÐµÑ‚ðŸ˜¢ \n",
    "#\n",
    "#ÐœÐ¾Ð¶Ð½Ð¾ Ð»Ð¸ ÐµÐ³Ð¾ Ð³Ð´Ðµ-Ñ‚Ð¾ Ð² Ð¢Ð±Ð¸Ð»Ð¸ÑÐ¸ ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ?\"\"\"\n",
    "#message = \"\"\"ÐšÐ¾Ñ‚Ð¸ÐºÐ¸, Ð° ÐµÑÑ‚ÑŒ Ð³Ð´Ðµ Ð² Ð¢Ð±Ð¸Ð»Ð¸ÑÐ¸ ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ Ð¿Ð¸Ñ‰ÐµÐ²ÑƒÑŽ Ð³Ð»Ð¸Ð½Ñƒ? \n",
    "#ÐÐµ Ð¼Ð½Ðµ, Ð¿Ð¾Ð´Ñ€ÑƒÐ³Ð° ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚\"\"\"\n",
    "#message =\"\"\"ÐŸÑ€Ð¸Ð²ÐµÑ‚!\n",
    "#\n",
    "#ÐŸÐ¾ÐºÐ° Ñ‡Ñ‚Ð¾ Ð¼ÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ Ð‘Ð°Ð±Ð°Ð¹ÐºÐ°. Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð¼Ð½Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ 1,5Ð¼ÐµÑÑÑ†Ð°. ÐœÐ°Ð¼Ð°-ÐºÐ¾ÑˆÐºÐ° Ð±Ñ€Ð¾ÑÐ¸Ð»Ð° Ð¼ÐµÐ½Ñ, Ð¸ Ñ Ð¿Ñ€Ð¾Ð²ÐµÐ»Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ñ€Ð°ÑˆÐ½Ñ‹Ñ… Ð´Ð½ÐµÐ¹ Ð¸ Ð½Ð¾Ñ‡ÐµÐ¹ Ð² Ð²Ð¾Ð´Ð¾ÑÑ‚Ð¾ÐºÐµ. Ð¯ Ð¼Ð½Ð¾Ð³Ð¾ ÐºÑ€Ð¸Ñ‡Ð°Ð»Ð° Ð¸ Ð¿Ð»Ð°ÐºÐ°Ð»Ð°, Ð·Ð°ÑÑ‹Ð¿Ð°Ð»Ð° Ð¾Ñ‚ Ð±ÐµÑÑÐ¸Ð»Ð¸Ñ, Ð½Ð¾ Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð²ÑÐµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÐ»Ð¾ÑÑŒ Ð²Ð½Ð¾Ð²ÑŒ.\n",
    "#Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð¼ÐµÐ½Ñ Ð·Ð°Ð±Ñ€Ð°Ð»Ð¸ Ðº ÑÐµÐ±Ðµ Ð›ÑŽÐ´Ð¸. ÐžÐ½Ð¸ Ð½Ð°ÑƒÑ‡Ð¸Ð»Ð¸ Ð¼ÐµÐ½Ñ ÐµÑÑ‚ÑŒ Ð¸Ð· Ð¼Ð¸ÑÐ¾Ñ‡ÐºÐ¸ Ð¸ Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒ Ð¿Ð¾ Ð´ÐµÐ»Ð°Ð¼ Ð² Ð»Ð¾Ñ‚Ð¾Ñ‡ÐµÐº. Ð ÐµÑ‰Ðµ Ð¾Ð½Ð¸ Ð½Ð°ÑƒÑ‡Ð¸Ð»Ð¸ Ð¼ÐµÐ½Ñ, Ñ‡Ñ‚Ð¾ Ð§ÐµÐ»Ð¾Ð²ÐµÐº Ð¸ ÐšÐ¾ÑˆÐºÐ° Ð¼Ð¾Ð³ÑƒÑ‚ Ð¿Ð¾Ð´Ð°Ñ€Ð¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³ Ð´Ñ€ÑƒÐ³Ñƒ Ð¼Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐ¿Ð»Ð°. Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ñ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾ ÐºÑƒÑˆÐ°ÑŽ Ð¿Ð°ÑˆÑ‚ÐµÑ‚Ñ‹ Ð¸ Ð¿Ð°ÑƒÑ‡Ð¸ Ð´Ð»Ñ ÐºÐ¾Ñ‚ÑÑ‚, ÑÐ»Ð°Ð´ÐºÐ¾ ÑÐ¿Ð»ÑŽ Ð¸ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¼Ð½Ð¾Ð³Ð¾ Ð¸Ð³Ñ€Ð°ÑŽ. Ð¯ Ð»ÑŽÐ±Ð»ÑŽ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒÑÑ Ñ€ÑÐ´Ð¾Ð¼ Ñ Ð»ÑŽÐ´ÑŒÐ¼Ð¸, Ð½Ð¾ Ð¼Ð½Ðµ Ð½Ðµ ÑÐºÑƒÑ‡Ð½Ð¾ Ð¸ Ð¾Ð´Ð½Ð¾Ð¹, Ð²ÐµÐ´ÑŒ Ñ Ð»ÑŽÐ±Ð¾Ð·Ð½Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¸ ÑÐ°Ð¼Ð¾ÑÑ‚Ð¾ÑÑ‚ÐµÐ»ÑŒÐ½Ð°Ñ.\n",
    "#Ð¯ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ…Ð¾Ñ‡Ñƒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð»ÑŽÐ±ÑÑ‰ÐµÐ³Ð¾ Ð§ÐµÐ»Ð¾Ð²ÐµÐºÐ° Ð¸ Ð±Ñ‹Ñ‚ÑŒ Ñ Ð½Ð¸Ð¼ Ð¾Ð´Ð½Ð¾Ð¹ ÑÐµÐ¼ÑŒÐµÐ¹. Ð¯ Ð¿Ð¾Ð´Ð°Ñ€ÑŽ Ð¼Ð½Ð¾Ð³Ð¾ Ð»Ð°ÑÐºÐ¸ Ð¸ Ð»ÑŽÐ±Ð²Ð¸ Ð²Ð·Ð°Ð¼ÐµÐ½ Ð½Ð° Ð´Ð¾Ð±Ñ€Ð¾Ñ‚Ñƒ. \n",
    "#\n",
    "#Ð¯ Ð½Ð°Ñ…Ð¾Ð¶ÑƒÑÑŒ Ð² Ð¢Ð±Ð¸Ð»Ð¸ÑÐ¸. Ð˜ ÑÐ¼Ð¾Ð³Ñƒ Ð¿Ñ€Ð¸ÐµÑ…Ð°Ñ‚ÑŒ Ðº Ð²Ð°Ð¼ Ð¿Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ñƒ, ÐµÑÐ»Ð¸ Ð²Ñ‹ Ñ€Ð°Ð·Ð³Ð»ÑÐ´ÐµÐ»Ð¸ Ð²Ð¾ Ð¼Ð½Ðµ ÑÐ²Ð¾Ðµ Ð±ÑƒÐ´ÑƒÑ‰ÐµÐµ Ð»ÑŽÐ±Ð¸Ð¼Ð¾Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾. \n",
    "#Ð’Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÑÐ¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ Ð¼ÐµÐ½Ñ Ð¿Ð¾ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ñƒ: +995 558 514 022 \n",
    "#Ð˜Ð»Ð¸ Ð½Ð°Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð² Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ\"\"\"\n",
    "#message = \"\"\"Ð’ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð²ÐµÑ‚, ÐºÑ‚Ð¾ Ð·Ð½Ð°ÐµÑ‚ Ð³Ð´Ðµ ÑÐµÐ¹Ñ‡Ð°Ñ ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ ÑÐ²ÐµÑ‚Ð»Ñ‹Ð¹ Ð¼Ð¸ÑÐ¾, Ð² ÑÐ°ÐºÑƒÑ€Ðµ Ð½ÐµÑ‚\"\"\"\n",
    "message = \"\"\"Ð”Ð¾Ð±Ñ€Ñ‹Ð¹ Ð²ÐµÑ‡ÐµÑ€ \n",
    "\n",
    "Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð° \n",
    "\n",
    "ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° Ð²ÐµÑ‚ÐµÑ€Ð¸Ð½Ð°Ñ€Ð¾Ð² Ð½Ð° Ð½Ð°ÑˆÐµÐ¹ ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ \n",
    "\n",
    "Ð‘ÑƒÐ´ÑƒÑ‚ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ð¿Ð¾ Ð²ÑÐµÐ¼ Ð¿ÑƒÐ½ÐºÑ‚Ð°Ð¼ Ð¿Ð¾ÑÑ‚Ð°\"\"\"\n",
    "prompt = get_prompt(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"products\": \"\"}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
